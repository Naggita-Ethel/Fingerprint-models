{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73632048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import TensorFlow and its components\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D, Dropout, Flatten, Dense, Add, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Import scikit-learn functions for model evaluation and data manipulation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Import imbalanced data handling library\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Import Keras utility for model loading\n",
    "from keras.models import load_model\n",
    "\n",
    "# Import OpenCV for image processing\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Import Keras utility for one-hot encoding\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445cf216",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model(\"RVA.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ce0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract labels from image filenames based on folder name\n",
    "def extract_label(img_path, train=True):\n",
    "    folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "    category = 0 if folder_name == 'Real' else 1\n",
    "    return np.array([category], dtype=np.uint16)\n",
    "# Define the size for image resizing\n",
    "img_size = 96\n",
    "\n",
    "# Define a function to load data from a given path\n",
    "def loading_data(path, boolean):\n",
    "    data = []\n",
    "    for img in os.listdir(path):\n",
    "        # Read and resize the image\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "        img_resize = cv2.resize(img_array, (img_size, img_size))\n",
    "        \n",
    "        # Extract label using the extract_label function\n",
    "        label = extract_label(os.path.join(path, img), boolean)\n",
    "        \n",
    "        # Append label and resized image to the data list\n",
    "        data.append([label[0], img_resize])\n",
    "        \n",
    "        # Print progress after processing 1000 images\n",
    "        if len(data) % 1000 == 0:\n",
    "            print(len(data))\n",
    "    return data\n",
    "# Load altered data from the \"Altered-Easy\" path using the loading_data function\n",
    "Altered_path = \"C:/Users/Pita/Desktop/python/machine learning/fingerprint_datasets/fingerprint_datasets/Altered/Altered-Easy\"\n",
    "altered_data = loading_data(Altered_path, True)\n",
    "\n",
    "# Split the altered dataset into two halves\n",
    "altered_half1 = altered_data[:len(altered_data) // 2]\n",
    "altered_half2 = altered_data[len(altered_data) // 2:]\n",
    "\n",
    "# Load real data from the \"Real\" path using the loading_data function\n",
    "Real_path = \"C:/Users/Pita/Desktop/python/machine learning/fingerprint_datasets/fingerprint_datasets/Real\"\n",
    "real_data = loading_data(Real_path, True)\n",
    "\n",
    "# Combine the first half of altered with real data for training\n",
    "x_train_real = [feature for label, feature in altered_half1]\n",
    "x_train_real += [feature for label, feature in real_data]\n",
    "y_train_real = [1] * len(altered_half1) + [0] * len(real_data)\n",
    "\n",
    "# Display class distribution before oversampling\n",
    "class_counts_before_resampling = pd.Series(y_train_real).value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=class_counts_before_resampling.index, y=class_counts_before_resampling.values)\n",
    "plt.title('Class Distribution Before Resampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()\n",
    "\n",
    "# Oversample the real data to balance classes\n",
    "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "x_train_real, y_train_real = shuffle(x_train_real, y_train_real, random_state=42)  # Shuffle real data before oversampling\n",
    "x_train_resampled, y_train_resampled = oversampler.fit_resample(np.array(x_train_real).reshape(-1, img_size * img_size), y_train_real)\n",
    "x_train_resampled = x_train_resampled.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "# Convert x_train_resampled and y_train_resampled to numpy arrays\n",
    "x_train_resampled = np.array(x_train_resampled)\n",
    "y_train_resampled = np.array(y_train_resampled)\n",
    "\n",
    "# Display class distribution after resampling\n",
    "class_counts_after_resampling = pd.Series(y_train_resampled).value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=class_counts_after_resampling.index, y=class_counts_after_resampling.values)\n",
    "plt.title('Class Distribution After Resampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()\n",
    "\n",
    "# Display a fingerprint image from the final training set\n",
    "plt.imshow(x_train_resampled[0].reshape(img_size, img_size), cmap='gray')\n",
    "plt.title('Fingerprint Image from Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd47dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the second half of altered with real data for training\n",
    "x_test_real = [feature for label, feature in altered_half2]\n",
    "x_test_real += [feature for label, feature in real_data]\n",
    "y_test_real = [1] * len(altered_half2) + [0] * len(real_data)\n",
    "\n",
    "# Display class distribution before oversampling\n",
    "class_counts_before_resampling = pd.Series(y_test_real).value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=class_counts_before_resampling.index, y=class_counts_before_resampling.values)\n",
    "plt.title('Class Distribution Before Resampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()\n",
    "\n",
    "# Oversample the real data to balance classes\n",
    "x_test_real, y_test_real = shuffle(x_test_real, y_test_real, random_state=42)  # Shuffle real data before oversampling\n",
    "x_test_resampled, y_test_resampled = oversampler.fit_resample(np.array(x_test_real).reshape(-1, img_size * img_size), y_test_real)\n",
    "x_test_resampled = x_test_resampled.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "# Convert x_test_resampled and y_test_resampled to numpy arrays\n",
    "x_test_resampled = np.array(x_test_resampled)\n",
    "y_test_resampled = np.array(y_test_resampled)\n",
    "\n",
    "# Display class distribution after resampling\n",
    "class_counts_after_resampling = pd.Series(y_test_resampled).value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=class_counts_after_resampling.index, y=class_counts_after_resampling.values)\n",
    "plt.title('Class Distribution After Resampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()\n",
    "\n",
    "# Display a fingerprint image from the final training set\n",
    "plt.imshow(x_test_resampled[0].reshape(img_size, img_size), cmap='gray')\n",
    "plt.title('Fingerprint Image from Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26408b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model2 using the prepared training data and labels\n",
    "history = model2.fit(\n",
    "    x_train_resampled,                  # Training images\n",
    "    y_train_resampled,                      # Training labels\n",
    "    batch_size=128,              # Number of samples in each training batch\n",
    "    epochs=24,                   # Number of training epochs\n",
    "    validation_split=0.2,        # Fraction of training data to use for validation\n",
    "    callbacks=[early_stopping_cb], # List of callbacks to be applied during training\n",
    "    verbose=1                    # Verbosity level: 1 shows progress bar\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model2 on the test set\n",
    "loss, accuracy = model2.evaluate(x_test_resampled, y_test_resampled)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predict labels on the test set\n",
    "preds = model2.predict(x_test_resampled)\n",
    "preds = (preds >= 0.5).astype(np.int32)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test_resampled, preds)\n",
    "df_cm = pd.DataFrame(cm, index=['Real', 'Altered'], columns=['Real', 'Altered'])\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Confusion Matrix for Gender Classification Model\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n",
    "\n",
    "# Compute classification report for precision, recall, F1-score, etc.\n",
    "class_report = classification_report(y_test_resampled, preds, target_names=['Real', 'Altered'])\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f213b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "model2.save('ARV2.keras')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
